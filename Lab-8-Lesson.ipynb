{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Lab 8 Lesson\n\n## Processing Data with Python, Part 2\n\n### Topics\n\n* exploring and summarizing data\n* data cleaning and manipulation\n* merging data\n* using time in pandas\n* working with WPRDC data"},{"metadata":{},"cell_type":"markdown","source":"# Some more data manipulation\n\nThere are a bunch of standard functions provided by pandas for manipulating data, and now that you've had a chance to get your feet wet, we're going to run through a bunch of things that you probably should know when doing data manipulation with pandas."},{"metadata":{},"cell_type":"markdown","source":"## More with exploring and summarizing data\n\nOnce your data has been loaded as a Dataframe, you can start using Pandas various functions to quickly explore your data "},{"metadata":{"trusted":true},"cell_type":"code","source":"# load pandas\nimport pandas as pd\nimport numpy as np\n\n# load data\ncenter_attendance_pandas = pd.read_csv(\"community-center-attendance.csv\", \n                                       index_col=\"_id\") # use the column named _id as the row index","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helpful functions for exploring DataFrames and Series"},{"metadata":{},"cell_type":"markdown","source":"Functions for looking at parts of the DataFrame include\n* `<dataframe>.head(n)` - look at the first n rows of the dataframe\n* `<dataframe>.tail(n)` - look at the last n rows of the dataframe\n* `<dataframe>.sample(n)` - randomly select n rows from the dataframe"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Look at the first 10 rows\ncenter_attendance_pandas.head(10)","execution_count":2,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>center_name</th>\n      <th>attendance_count</th>\n    </tr>\n    <tr>\n      <th>_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2018-06-08</td>\n      <td>Ormsby Community Center</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-06-08</td>\n      <td>Paulson Community Center</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-06-08</td>\n      <td>Phillips Community Center</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-06-08</td>\n      <td>Ammon Community Center</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2018-06-08</td>\n      <td>Brookline Community Center</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2018-06-08</td>\n      <td>Jefferson Community Center</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2018-06-08</td>\n      <td>Warrington Community Center</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2018-06-08</td>\n      <td>West Penn Community Center</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2018-06-07</td>\n      <td>Phillips Community Center</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2018-06-07</td>\n      <td>Paulson Community Center</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"           date                  center_name  attendance_count\n_id                                                           \n1    2018-06-08      Ormsby Community Center                10\n2    2018-06-08     Paulson Community Center                19\n3    2018-06-08    Phillips Community Center               107\n4    2018-06-08       Ammon Community Center                81\n5    2018-06-08   Brookline Community Center                33\n6    2018-06-08   Jefferson Community Center                29\n7    2018-06-08  Warrington Community Center                15\n8    2018-06-08   West Penn Community Center                54\n9    2018-06-07    Phillips Community Center                77\n10   2018-06-07     Paulson Community Center                25"},"execution_count":2,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Look at the last 5 rows\ncenter_attendance_pandas.tail()","execution_count":3,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>center_name</th>\n      <th>attendance_count</th>\n    </tr>\n    <tr>\n      <th>_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18363</th>\n      <td>2011-03-08</td>\n      <td>Magee Community Center</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>18364</th>\n      <td>2011-03-08</td>\n      <td>West Penn Community Center</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>18365</th>\n      <td>2011-03-07</td>\n      <td>Warrington Community Center</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18366</th>\n      <td>2011-03-07</td>\n      <td>Magee Community Center</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>18367</th>\n      <td>2011-03-07</td>\n      <td>West Penn Community Center</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"             date                  center_name  attendance_count\n_id                                                             \n18363  2011-03-08       Magee Community Center                32\n18364  2011-03-08   West Penn Community Center                 3\n18365  2011-03-07  Warrington Community Center                 1\n18366  2011-03-07       Magee Community Center                 7\n18367  2011-03-07   West Penn Community Center                 2"},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grab 5 random rows\ncenter_attendance_pandas.sample(5)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"             date                 center_name  attendance_count\n_id                                                            \n1413   2017-10-16      Magee Community Center                41\n11079  2014-01-24  West Penn Community Center                64\n5798   2016-02-12   Phillips Community Center                73\n78     2018-05-25     Ormsby Community Center                45\n14267  2012-11-19      Ammon Community Center                23","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>center_name</th>\n      <th>attendance_count</th>\n    </tr>\n    <tr>\n      <th>_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1413</th>\n      <td>2017-10-16</td>\n      <td>Magee Community Center</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>11079</th>\n      <td>2014-01-24</td>\n      <td>West Penn Community Center</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>5798</th>\n      <td>2016-02-12</td>\n      <td>Phillips Community Center</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>2018-05-25</td>\n      <td>Ormsby Community Center</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>14267</th>\n      <td>2012-11-19</td>\n      <td>Ammon Community Center</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Functions that let us count rows and columns include: \n* `<dataframe>.shape` - return the rows and columns as a python data structure (not a function!)\n* `<dataframe>.info()` - Display the datatypes of the index and columns as well as memory usage\n* `<dataframe>.describe()` - Compute summary statistics for numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many rows and columns\ncenter_attendance_pandas.shape","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(18367, 3)"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Inspect the datatypes\ncenter_attendance_pandas.info()","execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 18367 entries, 1 to 18367\nData columns (total 3 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   date              18367 non-null  object\n 1   center_name       18367 non-null  object\n 2   attendance_count  18367 non-null  int64 \ndtypes: int64(1), object(2)\nmemory usage: 574.0+ KB\n"}]},{"metadata":{},"cell_type":"markdown","source":"The output above shows us a lot of implementation details about our DataFrame. Data types, number of rows and columns, and the datatype of the column. It also shows us **memory usage**, which is useful because memory is a limited resource.\n\nFrom there, we can also start doing some computations on the data."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Compute summary statistics on the numerical columns\ncenter_attendance_pandas.describe()","execution_count":7,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attendance_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>18367.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>61.934883</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>58.510201</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>24.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>43.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>741.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       attendance_count\ncount      18367.000000\nmean          61.934883\nstd           58.510201\nmin            1.000000\n25%           24.000000\n50%           43.000000\n75%           80.000000\nmax          741.000000"},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"The `describe()` function will automatically compute summary statistics for numerical columns and ignore categorical columns."},{"metadata":{},"cell_type":"markdown","source":"### Counting Numerical Data\n\nOne of the things I mentioned last week is that pandas doesn't do anything that plain old Python can't. We can use traditional Python functions to get information about our Dataframe.\n\nThe `len()` function tells us the length of the sequence."},{"metadata":{"trusted":false},"cell_type":"code","source":"# use a standard python function to get the length of the sequence\nlen(center_attendance_pandas)","execution_count":8,"outputs":[{"data":{"text/plain":"18367"},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"So, this tells us our dataset has... a lot of rows. But this is just information about the dataset itself, it doesn't tell us how many people visited community centers.\n\nWhat if we wanted to know the total attendance: how many people visited all the community centers for all time (in the dataset)?\n\nFirst, let's answer this using pure Python."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Load up the CSV module and center attendance in python data structures\nimport csv\n\nwith open('community-center-attendance.csv') as f:\n    center_attendance_python = [row for row in csv.reader(f)]\n\n# look at the first ten rows of the data loaded in python\ncenter_attendance_python[0:10]","execution_count":9,"outputs":[{"data":{"text/plain":"[['_id', 'date', 'center_name', 'attendance_count'],\n ['1', '2018-06-08', 'Ormsby Community Center', '10'],\n ['2', '2018-06-08', 'Paulson Community Center', '19'],\n ['3', '2018-06-08', 'Phillips Community Center', '107'],\n ['4', '2018-06-08', 'Ammon Community Center', '81'],\n ['5', '2018-06-08', 'Brookline Community Center', '33'],\n ['6', '2018-06-08', 'Jefferson Community Center', '29'],\n ['7', '2018-06-08', 'Warrington Community Center', '15'],\n ['8', '2018-06-08', 'West Penn Community Center', '54'],\n ['9', '2018-06-07', 'Phillips Community Center', '77']]"},"execution_count":9,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# create a variable to hold the total attendance\ntotal_attendance = 0\n\n# loop over the data that was loaded using pure python\nfor row in center_attendance_python[1:]: # skip the header row using a list slice\n    # add the row count to the total, convert string to int\n    row_attendance = int(row[3])\n    total_attendance = total_attendance + row_attendance\n\nprint(total_attendance)","execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"1137558\n"}]},{"metadata":{},"cell_type":"markdown","source":"Now, here is how we do the exact same thing with Pandas.\n\nThis code selects the `attendance_count` column and then computes the sum of all the values."},{"metadata":{"trusted":false},"cell_type":"code","source":"# compute the total attendance with the pandas sum function\ncenter_attendance_pandas['attendance_count'].sum()","execution_count":11,"outputs":[{"data":{"text/plain":"1137558"},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"We can also look at the summary statistics individually, column-by-column.\n* `<dataframe>[<column name>].mean()` - calculate the mean value for the column values\n* `<dataframe>[<column name>].std()` - calculate the standard deviation for the column values\n* `<dataframe>[<column name>].var()` - calculate the variance value for the column values\n* `<dataframe>[<column name>].median()` - calculate the median value for the column values\n* `<dataframe>[<column name>].min()` - calculate the minimum value for the column values"},{"metadata":{"trusted":false},"cell_type":"code","source":"# mean attendance per day at all community centers\ncenter_attendance_pandas['attendance_count'].mean()","execution_count":12,"outputs":[{"data":{"text/plain":"61.93488321446072"},"execution_count":12,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# standard deviation\ncenter_attendance_pandas['attendance_count'].std()","execution_count":13,"outputs":[{"data":{"text/plain":"58.51020126797415"},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# variance\ncenter_attendance_pandas['attendance_count'].var()","execution_count":14,"outputs":[{"data":{"text/plain":"3423.4436524188445"},"execution_count":14,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# median attendance per day at all community centers\ncenter_attendance_pandas['attendance_count'].median()","execution_count":15,"outputs":[{"data":{"text/plain":"43.0"},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# minimum attendance at community centers\ncenter_attendance_pandas['attendance_count'].min()","execution_count":16,"outputs":[{"data":{"text/plain":"1"},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"**NOTE**: missing values are automatically skipped unless the entire column is NaN."},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.DataFrame([[1.4, None], [7.1, -4.5], \n                  [None, None], [0.75, -1.3]],\n                 index=['a','b','c','d'],\n                 columns=['one','two'])\ndf","execution_count":17,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>one</th>\n      <th>two</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>1.40</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>7.10</td>\n      <td>-4.5</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>0.75</td>\n      <td>-1.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    one  two\na  1.40  NaN\nb  7.10 -4.5\nc   NaN  NaN\nd  0.75 -1.3"},"execution_count":17,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.sum()","execution_count":18,"outputs":[{"data":{"text/plain":"one    9.25\ntwo   -5.80\ndtype: float64"},"execution_count":18,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.sum(axis=1)","execution_count":19,"outputs":[{"data":{"text/plain":"a    1.40\nb    2.60\nc    0.00\nd   -0.55\ndtype: float64"},"execution_count":19,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.mean(axis=1)","execution_count":20,"outputs":[{"data":{"text/plain":"a    1.400\nb    1.300\nc      NaN\nd   -0.275\ndtype: float64"},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.mean(axis=1, skipna=False)","execution_count":21,"outputs":[{"data":{"text/plain":"a      NaN\nb    1.300\nc      NaN\nd   -0.275\ndtype: float64"},"execution_count":21,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"### Math Operations\n\nYou can do mathematical operations that will get applied to every value in the row or column."},{"metadata":{"trusted":false},"cell_type":"code","source":"# create a numerical dataframe\ndf = pd.DataFrame([[1.4, 4.7], [7.1, -4.5], \n                  [3, 7], [0.75, -1.3]],\n                 index=['a','b','c','d'],\n                 columns=['one','two'])\ndf","execution_count":22,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>one</th>\n      <th>two</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>1.40</td>\n      <td>4.7</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>7.10</td>\n      <td>-4.5</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>3.00</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>0.75</td>\n      <td>-1.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    one  two\na  1.40  4.7\nb  7.10 -4.5\nc  3.00  7.0\nd  0.75 -1.3"},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# multiple two columns against eachother\ndf['one'] * df['two']","execution_count":23,"outputs":[{"data":{"text/plain":"a     6.580\nb   -31.950\nc    21.000\nd    -0.975\ndtype: float64"},"execution_count":23,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# divide a column by a number\ndf['one'] / 5","execution_count":24,"outputs":[{"data":{"text/plain":"a    0.28\nb    1.42\nc    0.60\nd    0.15\nName: one, dtype: float64"},"execution_count":24,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"However, there are, as you know, two major types of data: numerical and categorical. Pandas is not only a tool for working with numerical data. It has lots of functionality for manipulating categorical data, too."},{"metadata":{},"cell_type":"markdown","source":"### Counting Categorical Data\n\nJust like before, we can start counting the distribution of values in the column. \n\nHow many entries do we have per community center? (This isn't counting attendance, it's counting the number of *attendance counts* per center).\n\nFirst, let's do this in pure Python."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a dictionary to store the counts\ncenter_counter = dict()\n\n# loop over the data\nfor row in center_attendance_python[1:]:\n    center = row[2]\n    \n    # check to see if the gender is already in the diction\n    if center not in center_counter:\n        # create a new entry\n        center_counter[center] = 1\n    else:\n        # increment a new entry\n        #center_counter[center] += 1\n        center_counter[center] = center_counter[center] + 1\n\n# Display the dictionary \ncenter_counter","execution_count":25,"outputs":[{"data":{"text/plain":"{'Ormsby Community Center': 1990,\n 'Paulson Community Center': 1547,\n 'Phillips Community Center': 2116,\n 'Ammon Community Center': 1825,\n 'Brookline Community Center': 2159,\n 'Jefferson Community Center': 1701,\n 'Warrington Community Center': 1714,\n 'West Penn Community Center': 2130,\n 'Magee Community Center': 1800,\n 'Arlington Community Center': 1331,\n 'Gladstone Field': 5,\n 'Mellon Tennis Center': 6,\n 'Phillips Park Field': 13,\n 'Schenley Ice Rink': 1,\n 'Warrington Field': 1,\n 'West Penn Fields': 1,\n 'West Penn Pool': 7,\n 'Dan Marino Field (Playground)': 1,\n 'Paulson Field': 3,\n 'Ormsby Field (Playground)': 8,\n 'Ammon Pool': 3,\n 'Moore Pool': 1,\n 'Frick Environmental Center': 1,\n 'Arlington Field (Playground)': 1,\n 'Highland Pool': 1,\n 'Ammon / Josh Gibson Field': 1}"},"execution_count":25,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"The Pandas way, as usualy, is a bit easier."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Do the same thing with pandas\ncenter_attendance_pandas['center_name'].value_counts()","execution_count":26,"outputs":[{"data":{"text/plain":"Brookline Community Center       2159\nWest Penn Community Center       2130\nPhillips Community Center        2116\nOrmsby Community Center          1990\nAmmon Community Center           1825\nMagee Community Center           1800\nWarrington Community Center      1714\nJefferson Community Center       1701\nPaulson Community Center         1547\nArlington Community Center       1331\nPhillips Park Field                13\nOrmsby Field (Playground)           8\nWest Penn Pool                      7\nMellon Tennis Center                6\nGladstone Field                     5\nAmmon Pool                          3\nPaulson Field                       3\nFrick Environmental Center          1\nArlington Field (Playground)        1\nDan Marino Field (Playground)       1\nMoore Pool                          1\nHighland Pool                       1\nWest Penn Fields                    1\nWarrington Field                    1\nSchenley Ice Rink                   1\nAmmon / Josh Gibson Field           1\nName: center_name, dtype: int64"},"execution_count":26,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"center_attendance_pandas['center_name'].value_counts().sort_values(ascending=True)","execution_count":27,"outputs":[{"data":{"text/plain":"Ammon / Josh Gibson Field           1\nWarrington Field                    1\nWest Penn Fields                    1\nHighland Pool                       1\nMoore Pool                          1\nDan Marino Field (Playground)       1\nArlington Field (Playground)        1\nFrick Environmental Center          1\nSchenley Ice Rink                   1\nPaulson Field                       3\nAmmon Pool                          3\nGladstone Field                     5\nMellon Tennis Center                6\nWest Penn Pool                      7\nOrmsby Field (Playground)           8\nPhillips Park Field                13\nArlington Community Center       1331\nPaulson Community Center         1547\nJefferson Community Center       1701\nWarrington Community Center      1714\nMagee Community Center           1800\nAmmon Community Center           1825\nOrmsby Community Center          1990\nPhillips Community Center        2116\nWest Penn Community Center       2130\nBrookline Community Center       2159\nName: center_name, dtype: int64"},"execution_count":27,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"There are a bunch of other functions for working with categorical data."},{"metadata":{"trusted":false},"cell_type":"code","source":"center_attendance_pandas['center_name'].unique()","execution_count":28,"outputs":[{"data":{"text/plain":"array(['Ormsby Community Center', 'Paulson Community Center',\n       'Phillips Community Center', 'Ammon Community Center',\n       'Brookline Community Center', 'Jefferson Community Center',\n       'Warrington Community Center', 'West Penn Community Center',\n       'Magee Community Center', 'Arlington Community Center',\n       'Gladstone Field', 'Mellon Tennis Center', 'Phillips Park Field',\n       'Schenley Ice Rink', 'Warrington Field', 'West Penn Fields',\n       'West Penn Pool', 'Dan Marino Field (Playground)', 'Paulson Field',\n       'Ormsby Field (Playground)', 'Ammon Pool', 'Moore Pool',\n       'Frick Environmental Center', 'Arlington Field (Playground)',\n       'Highland Pool', 'Ammon / Josh Gibson Field'], dtype=object)"},"execution_count":28,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(center_attendance_pandas['center_name'].unique())","execution_count":29,"outputs":[{"data":{"text/plain":"26"},"execution_count":29,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"# Data wrangling, databases, and subsetting\n\nIt is sometimes helpful to think of a Pandas DataFrame as a little database. There is data and information stored in the Pandas DataFrame (or Series) and you want to *retrieve* it.\n\nPandas has multiple mechanisms for getting specific bits of data and information from its data structures. \n\n## Masking: Filtering by Values\n\nThe most common is to use *masking* to select just the rows you want. \n\nMasking is a two stage process, first you create a sequence of boolean values based upon a conditional expression—which you can think of as a \"query\"—and then you index your dataframe using that boolean sequence. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's look at the chipotle order data\norder_data = pd.read_csv('chipotle.tsv', sep='\\t')\norder_data.head(10)","execution_count":32,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>quantity</th>\n      <th>item_name</th>\n      <th>choice_description</th>\n      <th>item_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Chips and Fresh Tomato Salsa</td>\n      <td>NaN</td>\n      <td>2.39</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Izze</td>\n      <td>[Clementine]</td>\n      <td>3.39</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Nantucket Nectar</td>\n      <td>[Apple]</td>\n      <td>3.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Chips and Tomatillo-Green Chili Salsa</td>\n      <td>NaN</td>\n      <td>2.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Chicken Bowl</td>\n      <td>[Tomatillo-Red Chili Salsa (Hot), [Black Beans...</td>\n      <td>16.98</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Chicken Bowl</td>\n      <td>[Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...</td>\n      <td>10.98</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Side of Chips</td>\n      <td>NaN</td>\n      <td>1.69</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Steak Burrito</td>\n      <td>[Tomatillo Red Chili Salsa, [Fajita Vegetables...</td>\n      <td>11.75</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Steak Soft Tacos</td>\n      <td>[Tomatillo Green Chili Salsa, [Pinto Beans, Ch...</td>\n      <td>9.25</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5</td>\n      <td>1</td>\n      <td>Steak Burrito</td>\n      <td>[Fresh Tomato Salsa, [Rice, Black Beans, Pinto...</td>\n      <td>9.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   order_id  quantity                              item_name  \\\n0         1         1           Chips and Fresh Tomato Salsa   \n1         1         1                                   Izze   \n2         1         1                       Nantucket Nectar   \n3         1         1  Chips and Tomatillo-Green Chili Salsa   \n4         2         2                           Chicken Bowl   \n5         3         1                           Chicken Bowl   \n6         3         1                          Side of Chips   \n7         4         1                          Steak Burrito   \n8         4         1                       Steak Soft Tacos   \n9         5         1                          Steak Burrito   \n\n                                  choice_description  item_price  \n0                                                NaN        2.39  \n1                                       [Clementine]        3.39  \n2                                            [Apple]        3.39  \n3                                                NaN        2.39  \n4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...       16.98  \n5  [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...       10.98  \n6                                                NaN        1.69  \n7  [Tomatillo Red Chili Salsa, [Fajita Vegetables...       11.75  \n8  [Tomatillo Green Chili Salsa, [Pinto Beans, Ch...        9.25  \n9  [Fresh Tomato Salsa, [Rice, Black Beans, Pinto...        9.25  "},"execution_count":32,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's look at all the columns\norder_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we only wanted to look at a **specific order**? Let's try and isolate just the orders for chicken bowls.\n\nFirstly, create a *query mask*, a list of `True/False` values for rows that satisfy a particular condition."},{"metadata":{"trusted":false},"cell_type":"code","source":"# create a query mask for chicken bowls\nquery_mask = order_data['item_name'] == \"Chicken Bowl\"\n\n#look at the first 20 items to see what matches\nquery_mask.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This tells us the *row id* and True or False if the item is a chicken bowl.\n\nLet's just test to see if this is correct:"},{"metadata":{"trusted":false},"cell_type":"code","source":"order_data.iloc[19]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yup! So now that we know the mask works, we can create a *subset* of our data containing chicken bowls."},{"metadata":{"trusted":false},"cell_type":"code","source":"chicken_bowls = order_data[query_mask]\nchicken_bowls.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, you've got just the orders for chicken bowls, so you can do data operations on *just* those orders."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate the mean price for chicken bowls\nchicken_bowls['item_price'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# See how many chicken bowls people order\nchicken_bowls['quantity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also combine query masks using **boolean logic**. Can we look at just the chicken bowl orders that were less than $10?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# create a query mask for chicken bowls\nitem_query_mask = order_data['item_name'] == \"Chicken Bowl\"\n# create a query mask for cheap orders\nprice_query_mask = order_data['item_price'] < 10\n\n# apply both query masks using boolean AND\ncheap_chicken_bowls = order_data[item_query_mask & price_query_mask]\ncheap_chicken_bowls.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Median price for cheap chicken bowls\ncheap_chicken_bowls['item_price'].median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Query masks can be used to filter and create subsets of data.\n\n**NOTE**: this method of subsetting data creates what is called a \"view\" of the data. You are basically working with a big slice of the original dataframe, *not* a separate copy of the data.\n\nThis means if you try an do transformations on that view, you will get an error. For more information, [see the pandas documentation](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy).\n\nIf you do want to do transformations on this data, it's trivial to make a copy, though."},{"metadata":{"trusted":false},"cell_type":"code","source":"cheap_chicken_bowls['half_price'] = cheap_chicken_bowls['item_price'] / 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"copy_of_cheap_chicken_bowls = cheap_chicken_bowls.copy()\ncopy_of_cheap_chicken_bowls['half_price'] = copy_of_cheap_chicken_bowls['item_price'] / 2\ncopy_of_cheap_chicken_bowls.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging Data\n\nBringing disparate datasets together is one of the more powerful features of pandas.\n\nLike with Python lists, you can `append()` and `concat()` pandas Series and Dataframes. The `concat` is a module function, you call it directly from the pandas module (usually called `pd`)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatinate two series together\nser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\nser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\npd.concat([ser1, ser2]) \n# note the Series are passed as a list","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# order matters\npd.concat([ser2, ser1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatinate two dataframes\ndf1 = pd.DataFrame({\"A\":[\"A1\", \"A2\"],\n                    \"B\":[\"B1\",\"B2\"]},index=[1,2])\ndf2 = pd.DataFrame({\"A\":[\"A3\", \"A4\"],\n                    \"B\":[\"B3\",\"B4\"]},index=[3,4])\npd.concat([df1,df2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pandas will automatically handle lining up matching indices."},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatinate dataframes horizontally\ndf1 = pd.DataFrame({\"A\":[\"A1\", \"A2\"],\n                    \"B\":[\"B1\",\"B2\"]},index=[1,2])\ndf2 = pd.DataFrame({\"C\":[\"C1\", \"C2\"],\n                    \"D\":[\"D1\",\"D2\"]},index=[1,2])\npd.concat([df1,df2], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And pandas will gracefully handle misalignment."},{"metadata":{"trusted":false},"cell_type":"code","source":"# What happens when indexes don't line up\ndf1 = pd.DataFrame({\"A\":[\"A1\", \"A2\"],\n                    \"B\":[\"B1\",\"B2\"]},index=[1,2])\ndf2 = pd.DataFrame({\"A\":[\"A3\", \"A4\"],\n                    \"B\":[\"B3\",\"B4\"]},index=[3,4])\npd.concat([df1,df2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# create a hierarchical index\ndf1 = pd.DataFrame({\"A\":[\"A1\", \"A2\"],\n                    \"B\":[\"B1\",\"B2\"]},index=[1,2])\ndf2 = pd.DataFrame({\"A\":[\"A3\", \"A4\"],\n                    \"B\":[\"B3\",\"B4\"]},index=[3,4])\npd.concat([df1,df2], keys=[\"df1\", 'df2'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `append` function is a method of a Series/Dataframe and returns a new object."},{"metadata":{"trusted":false},"cell_type":"code","source":"# append df2 to df1\ndf1.append(df2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Joins: more powerful concatenation\n\nWhile `concat()` is useful, it lacks the power to do complex data merging.\n\nFor example, let's say I have two tables of different data but one overlapping column.\n\nThis is where the `merge()` function becomes useful because it lets you *join* datasets\n\nThe concept of \"join\" has lots of theory and is a richly developed method for *joining* data."},{"metadata":{},"cell_type":"markdown","source":"### One-to-one joins"},{"metadata":{"trusted":false},"cell_type":"code","source":"# create two dataframes with one shared column\ndf1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue', \"Nancy\"],\n                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR', \"Librarian\"]})\ndf2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n                    'hire_date': [2004, 2008, 2012, 2014]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# display df1\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# display df2\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# merge df1 and df2 into a new dataframe df3\ndf3 = pd.merge(df1, df2)\ndf3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new dataframe `df3` now has all of the data from df1 and df2.\n\nThe `merge` function automatically connected the two tables on the \"employee\" column.\n\nBut what happens when your data don't line up?"},{"metadata":{},"cell_type":"markdown","source":"### Many-to-one joins\n\nSometimes, there isn't a one to one relationshp between rows in the two datasets.\n\nA *many-to-one* join lets you combine these datasets."},{"metadata":{"trusted":false},"cell_type":"code","source":"df3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# make another dataframe about the supervisor for each group\ndf4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n                    'supervisor': ['Carly', 'Guido', 'Steve']})\ndf4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Merge df3 from above with the supervisor info in df4\npd.merge(df3,df4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how the information about Guido, the manager for Engineering, is repeated.\n\nPandas automatically fills in these values to maintain the tabular, 2 dimensional structure of the data.\n\nWhile this might seem like duplicated data, it makes it easier to quickly look up Jake and Lisa's supervisor without consulting multiple tables. It's sometimes better to duplicate data to have it arranged in a way that you want.\n\nNow, let's make it even more complicated."},{"metadata":{},"cell_type":"markdown","source":"### Many-to-many joins\n\nLet's combine the employee information with skills information.\n\nNotice there isn't a one-to-one or even a one-to-many relationship between these tables.\n\nEach group can have multiple skills, so **what do you think will happen?**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Use the employee table specified above\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# create a new dataframe with skills information\ndf5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n                              'Engineering', 'Engineering', 'HR', 'HR', 'Librarian'],\n                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n                               'spreadsheets', 'organization', 'nunchucks']})\ndf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# what's going to happen?\npd.merge(df1, df5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Amazing!\n\n![whoa dude](https://media.giphy.com/media/Lcn0yF1RcLANG/giphy.gif)\n\nPandas merge capabilities are very useful.\n\nBut what do you do if the names of your columns don't match? You could change column names.\n\nBut that's crazy! Just use the `left_on` and `right_on` parameters to the `merge()` function."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Use the employee table specified above\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a new salary table, but use \"name\" instead of \"employee\" for the column index\ndf3 = df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue','Nancy'],\n                    'salary': [70000, 80000, 120000, 90000,1000000]})\ndf3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# lets try and merge them without specifying what to merge on\npd.merge(df1, df3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are the column names I should specify here?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Now lets specify the column name \npd.merge(df1, df3, left_on=\"employee\", right_on=\"name\" )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice we now have a redundant employee/name column; this is a by-product of merging different columns.\n\nIf you want to get rid of it, that's trivial: you can use the `drop` method."},{"metadata":{"trusted":false},"cell_type":"code","source":"# drop the name column, axis=1 means axis='col', which is confusing\npd.merge(df1, df3, left_on=\"employee\", right_on=\"name\" ).drop(\"name\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Like I said, there is a ton of theory around merging and joining data, so this is just us dipping our toes in."},{"metadata":{},"cell_type":"markdown","source":"# `groupby()` and aggregation\n\nWe looked at the `groupby()` function last week, and I don't want to waste time on it today. Essentially, `groupby()` lets you group all of the items in a DataFrame by a single column.\n\nThere's a bunch of other ways to sort data in DataFrames with pandas. The following table summarizes some other built-in Pandas aggregations:\n\n| Aggregation              | Description                     |\n|--------------------------|---------------------------------|\n| ``count()``              | Total number of items           |\n| ``size()``               | Total number of items w/ NaNs   |\n| ``first()``, ``last()``  | First and last item             |\n| ``mean()``, ``median()`` | Mean and median                 |\n| ``min()``, ``max()``     | Minimum and maximum             |\n| ``std()``, ``var()``     | Standard deviation and variance |\n| ``mad()``                | Mean absolute deviation         |\n| ``prod()``               | Product of all items            |\n| ``sum()``                | Sum of all items                |\n\nThese are all functions of ``DataFrame`` and ``Series`` objects.\n\nYou can also do multiple levels of grouping with something called [Multilevel Indexing](https://pandas.pydata.org/pandas-docs/stable/advanced.html). Unfortunately, we don't have time to go in depth into this, but the Python Data Science Handbook (one of your textbooks for the course) has a great intro to the topic in the chapter [Hierarchical Indexing](https://jakevdp.github.io/PythonDataScienceHandbook/03.05-hierarchical-indexing.html).\n"},{"metadata":{},"cell_type":"markdown","source":"# Now, let's work with some real data\n\nThe WPRDC, which stands for Western Pennsylvania Regional Data Center, is *the* place to go for data around Pittsburgh. You'll be working with WPRDC data for your final project (*wink, wink*).\n\nSo, let's grab the [Allegheny County Jail's daily census](https://data.wprdc.org/dataset/allegheny-county-jail-daily-census) from the WPRDC."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Grab three months of data\njanuary17_jail_census = pd.read_csv(\"https://data.wprdc.org/datastore/dump/3b5d9c45-b5f4-4e05-9cf1-127642ad1d17\")\nfeburary17_jail_census = pd.read_csv(\"https://data.wprdc.org/datastore/dump/cb8dc876-6285-43a8-9db3-90b84eedb46f\")\nmarch17_jail_census = pd.read_csv(\"https://data.wprdc.org/datastore/dump/68645668-3f89-4831-b1de-de1e77e52dd3\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"january17_jail_census.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Use the concat function to combine all three into one dataframe\n# Remember I need to make a list of the all the dataframes for\n# the concat fuction\njail_census = pd.concat([january17_jail_census, \n                         feburary17_jail_census, \n                         march17_jail_census])\njail_census","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even though these aren't *really* valid computations because we are looking at a daily census, we can still use these data for demonstration purposes."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Compute the average age at booking by gender\njail_census.groupby('Gender')['Age at Booking'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# compute the average age at booking by race then gender \njail_census.groupby(['Race', 'Gender'])['Age at Booking'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we look at the [data dictionary](https://data.wprdc.org/dataset/allegheny-county-jail-daily-census/resource/f0550174-16b0-4f6e-88dc-fa917e74b56c), we can see the following mapping for race categories:\n```\nRace of Inmate\nA-ASIAN OR PACIFIC ISLANDER\nB-BLACK OR AFRICAN AMERICAN\nH-HISPANIC \nI-AMERICAN INDIAN OR ALASKAN NATIVE\nU-UNKNOWN\nW-WHITE\n```\nThe `x` category hasn't been described."},{"metadata":{"trusted":false},"cell_type":"code","source":"# how many total rows in the dataset have \"x\" for race\njail_census['Race'].value_counts()['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get the statistical summary of age at booking by gender\njail_census.groupby('Gender')['Age at Booking'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Compute the difference between Age at Booking and current age\nage_difference = jail_census['Current Age'] - jail_census['Age at Booking']\nage_difference.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's sort them by date, so we can see who was there on any given day."},{"metadata":{"trusted":false},"cell_type":"code","source":"jail_census.groupby('Date').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"jail_census['year'] = jail_census['Date'].str.split(\"-\").str[0]\njail_census['month'] = jail_census['Date'].str.split(\"-\").str[1]\njail_census['day'] = jail_census['Date'].str.split(\"-\").str[2]\n\njail_census.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"jail_census.groupby('month').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"jail_census.groupby('day').count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a really awkward way of dealing with time. We shouldn't have to make a separate column for year, month, day.\n\nThere must be a better way to do this time stuff... any ideas?"},{"metadata":{},"cell_type":"markdown","source":"# One more thing\n\nBefore we get into doing some real-world data manipulation, I want to briefly dive into working with time in pandas. One of the most powerful features of pandas is its time series functionality.\n\nDates and time are a Python and pandas data type (like integers and strings). By using the `datetime` data types you can do advanced, time-centric analysis.\n\nOne thing to remember about computers is they are *very* specific. The following things are *all different* to the computer:\n\n* **time stamps** - a specific moment in time (July 4th, 2017 at 7:52am and 34 seconds)\n* **time intervals** - a length of time with start and end points (the year 2017)\n* **time duration** - a specific length of time (a year, a month, a day)\n   \nPandas has its own data types for time (much like Series and DataFrame). If you have a lot of dates, it is often useful to use the Pandas functions over the native Python functions. Pandas is most powerful when you index by time using the `DatetimeIndex`."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a Series with a DateTime index\nindex = pd.DatetimeIndex(['2014-03-04', '2014-08-04',\n                          '2015-04-04', '2015-09-04',\n                          '2016-01-01', '2016-02-16'])\ndata = pd.Series([0, 1, 2, 3, 4, 5], index=index)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the index is made of DateTimes, we can index using date strings.\n\n**NOTE**: this only works on strings."},{"metadata":{"trusted":false},"cell_type":"code","source":"# grab the value for a specific day\ndata[\"2015-04-04\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# grab a slice between two dates\ndata['2014-08-01':'2016-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# give me everything from 2015\ndata['2015']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pandas has some functions to make parsing dates easy, as well."},{"metadata":{"trusted":false},"cell_type":"code","source":"# use the to_datetime function instead of the parser function\ndate = pd.to_datetime(\"4th of July, 2017\")\ndate","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# use string format codes to get the weekday\ndate.strftime(\"%A\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# give me today's date\ntoday = pd.to_datetime(\"today\")\ntoday","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That is the day, but also the exact time. Remember? Computers are picky. Timestamps must always be a *specific moment*."},{"metadata":{},"cell_type":"markdown","source":"## Working with Time on Real Data\n\nLet's look at the [311 data for the city of Pittsburgh](https://data.wprdc.org/dataset/311-data) from the WPRDC. Did you know, you can give the URL directly to Pandas!"},{"metadata":{"trusted":false},"cell_type":"code","source":"# load the 311 data directly from the WPRDC\npgh_311_data = pd.read_csv(\"https://data.wprdc.org/datastore/dump/76fda9d0-69be-4dd5-8108-0de7907fc5a4\")\npgh_311_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Inspect the dataframe and Pandas automatic data type detection\npgh_311_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay, now we have the data, but we need it to be indexed by date.\n\n* **What column has the date information?**\n* **What format do you think that column is currently in?**\n* **What function might we use to convert that column into dates?**"},{"metadata":{"trusted":false},"cell_type":"code","source":"pgh_311_data['CREATED_ON'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# convert the \"CREATED_ON\" column to dates\npd.to_datetime(pgh_311_data['CREATED_ON']).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can convert the \"CREATED_ON\" column to Pandas `datetime` objects, and now we have to set that to the dataframe's index."},{"metadata":{"trusted":false},"cell_type":"code","source":"# set the index of pgh_311_data to be the parsed dates in the \"CREATED_ON\" column\npgh_311_data.index = pd.to_datetime(pgh_311_data['CREATED_ON'])\npgh_311_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Huh, now we have CREATED_ON twice. That isn't very tidy. We can also skip this extra conversion step entirely by specifying the index column and date parsing in `read_csv()` function call."},{"metadata":{"trusted":false},"cell_type":"code","source":"# load the 311 data directly from the WPRDC and parse dates directly\npgh_311_data = pd.read_csv(\"https://data.wprdc.org/datastore/dump/76fda9d0-69be-4dd5-8108-0de7907fc5a4\",\n                           index_col=\"CREATED_ON\", \n                           parse_dates=True)\npgh_311_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pgh_311_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the dataframe has been indexed by time, we can select 311 complains by time!"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Select 311 complaints on January 1st, 2016\npgh_311_data['2016-01-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Select the times just around the new years celebration\npgh_311_data[\"2015-12-31 20:00:00\":\"2016-01-01 02:00:00\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Someone had a fun New Year's. "},{"metadata":{},"cell_type":"markdown","source":"## Resampling\n\nLast week, we \"smoothed over\" the community center data by using the `resample()` method. Let's do that some more, shall we?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# count the number of complaints per month\npgh_311_data.resample(\"M\").size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# compute the mean of complaints per quarter...note this doesn't make sense, but works anyway\npgh_311_data.resample(\"Q\").mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot this. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Tell matplotlib to render plots inline\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a graph of the monthly complaint counts\npgh_311_data['REQUEST_ID'].resample(\"M\").count().plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try the code above, but re-sampling based upon different date periods. The strings for specifying an offset are located [here](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases) and below:\n\n|Alias|Description|\n|-----|-----------|\n|B|business day frequency|\n|C|custom business day frequency|\n|D|calendar day frequency|\n|W|weekly frequency|\n|M|month end frequency|\n|SM|semi-month end frequency (15th and end of month)|\n|BM|business month end frequency|\n|CBM|custom business month end frequency|\n|MS|month start frequency|\n|SMS|semi-month start frequency (1st and 15th)|\n|BMS|business month start frequency|\n|CBMS|custom business month start frequency|\n|Q|quarter end frequency|\n|BQ|business quarter end frequency|\n|QS|quarter start frequency|\n|BQS|business quarter start frequency|\n|A, Y|year end frequency|\n|BA, BY|business year end frequency|\n|AS, YS|year start frequency|\n|BAS, BYS|business year start frequency|\n|BH|business hour frequency|\n|H|hourly frequency|\n|T, min|minutely frequency|\n|S|secondly frequency|\n|L, ms|milliseconds|\n|U, us|microseconds|\n|N|nanoseconds|"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Try a different resampling here\n\npgh_311_data['REQUEST_ID'].resample(\"SOMETHING DIFFERENT\").count().plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Try yet another resampling here\n\npgh_311_data['REQUEST_ID'].resample(\"EVEN MORE DIFFERENT\").count().plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wrapping up\n\nOkay, so that's pandas. We'll get a little bit more into some specifics next week when we talk about data visualization. We'll be using pandas, geopandas, and matplotlib to answer some interesting questions with data. "}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"0.11.9"}},"nbformat":4,"nbformat_minor":4}